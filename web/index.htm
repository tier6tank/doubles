<html>

<head><title> Duplicate Files Finder</title></head>

<body style="font-family:Arial,sans-serif">

<h1>Duplicate Files Finder</h1>

<a name="Introduction"><h2>Introduction</h2></a>

Duplicate Files Finder is a program which searches (as the name says) for 
duplicate files. It uses a <a href="#Algorithm">special algorithm</a> to find duplicate files, which 
is much faster than the algorithm used by most programs of that sort (hashing); yet it compares the
content of the files, not only the names. <br>
It offers as well many options to get rid of duplicate files. You can either delete duplicate files, 
or create hardlinks or symbolic links (if supported by the operating system). All this can 
directly be done in the program. 

<a name="Download"><h2>Download</h2>

<ul>
<li>Windows users can download the 
<a href="http://sourceforge.net/project/platformdownload.php?group_id=211415&sel_platform=6515">installer</a>. 
<li>Linux users who want to compile the program themselves, can download the 
<a href="http://sourceforge.net/project/platformdownload.php?group_id=211415&sel_platform=8737">source</a> 
(and binaries, if you want, but no installer is included!)

<li>Binary rpm packages for (open)SuSE you find on 
<a href="http://packman.links2linux.de/package/dupfinder">this page</a>.

<li>For debian, there isn't any .deb file distribution i know of (sorry). 
</ul>

<a name="SuppPlatforms"><h2>Platforms supported</h2></a>

Duplicate Files Finder supports the following platforms:

<ul>
 <li>The Windows 9x family (Windows 95, 98, ME)</li>
 <li>The Windows NT family (Windows NT, XP, 2000, Vista)</li>
 <li>POSIX-like operating systems (Unix, Linux)</li>
</ul>


<a name="Features"><h2>Features</h2></a>

<ul>
 <li>Byte by byte comparison</li>
 <li>Very fast search</li>
 <li>Support for hardlinks and symbolic links</li>
 <li>User interface to process the results by deleting duplicate files, or creating links</li>
 <li>Many search options</b>
</ul>

<a name="Algorithm"><h2>Short description of the algorithm</h2>

The algorithm is as follows: First, all files are sorted by their size, because files can be
only equal, if they have the same size (logically). <br>
Then the files are compared with each other, and thus the equal files are determined. If two
files are not equal from a given point, reading is interrupted; no more has to be read for 
determining that these files are not equal. <br>
Additional caching of the contents of the files additionally improves performance.

<a name="Links"><h2>Links</h2></a>

<ul>
 <li><a href="http://sourceforge.net/projects/doubles">Sourceforge project page</a></li>
 <li><a href="http://sourceforge.net/project/screenshots.php?group_id=211415">Screenshots</a></li>
 <li><a href="http://sourceforge.net/project/platformdownload.php?group_id=211415">Download Duplicate Files Finder</a></li>
</ul> 

<hr></hr>

<a href="http://sourceforge.net"><img src="http://sflogo.sourceforge.net/sflogo.php?group_id=211415&amp;type=2" width="125" height="37" border="0" alt="SourceForge.net Logo" /></a>

</body>

</html>